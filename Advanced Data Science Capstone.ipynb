{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "**Advanced Data Science capstone project** \\\nFor this capstone project, we use a dataset regarding celestial object measurements and their classification into three possible candidates: a galaxy, a star or a quasar. Before we go further, we need to install pyspark, keras and tensorflow libraries for setting the model, as they are not already installed."}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "!pip install tensorflow==2.2\n!pip install keras\n!pip install pyspark==2.4.5", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Collecting tensorflow==2.2\n  Downloading tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 516.2 MB 6.8 kB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==2.2) (1.27.2)\nRequirement already satisfied: google-pasta>=0.1.8 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==2.2) (0.2.0)\nCollecting gast==0.3.3\n  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==2.2) (3.1.0)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==2.2) (0.34.2)\nCollecting scipy==1.4.1; python_version >= \"3\"\n  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 26.1 MB 52.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==2.2) (0.9.0)\nRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==2.2) (2.10.0)\nCollecting astunparse==1.6.3\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==2.2) (1.18.5)\nRequirement already satisfied: protobuf>=3.8.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==2.2) (3.12.3)\nCollecting tensorboard<2.3.0,>=2.2.0\n  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.0 MB 58.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==2.2) (1.1.0)\nCollecting tensorflow-estimator<2.3.0,>=2.2.0\n  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 454 kB 62.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==2.2) (1.12.1)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==2.2) (1.1.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==2.2) (1.15.0)\nRequirement already satisfied: setuptools in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow==2.2) (47.3.1.post20200622)\nCollecting tensorboard-plugin-wit>=1.6.0\n  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 779 kB 63.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.22.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.24.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.0.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.1.1)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.6)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.2.8)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.1.1)\nRequirement already satisfied: aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\" in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.6.2)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.3.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.25.9)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2020.11.8)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.0.4)\nRequirement already satisfied: pyasn1>=0.1.3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.8)\nRequirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.0.1)\nRequirement already satisfied: multidict<5.0,>=4.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.7.6)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (19.3.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.1.0)\nRequirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.7.4.2)\nInstalling collected packages: gast, scipy, astunparse, tensorboard-plugin-wit, tensorboard, tensorflow-estimator, tensorflow\n  Attempting uninstall: gast\n    Found existing installation: gast 0.2.2\n    Uninstalling gast-0.2.2:\n      Successfully uninstalled gast-0.2.2\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.5.0\n    Uninstalling scipy-1.5.0:\n      Successfully uninstalled scipy-1.5.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.1.0\n    Uninstalling tensorboard-2.1.0:\n      Successfully uninstalled tensorboard-2.1.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.1.0\n    Uninstalling tensorflow-estimator-2.1.0:\n      Successfully uninstalled tensorflow-estimator-2.1.0\n", "name": "stdout"}, {"output_type": "stream", "text": "  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.1.0\n    Uninstalling tensorflow-2.1.0:\n      Successfully uninstalled tensorflow-2.1.0\nSuccessfully installed astunparse-1.6.3 gast-0.3.3 scipy-1.4.1 tensorboard-2.2.2 tensorboard-plugin-wit-1.7.0 tensorflow-2.2.0 tensorflow-estimator-2.2.0\nCollecting keras\n  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\nRequirement already satisfied: h5py in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras) (2.10.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras) (1.18.5)\nRequirement already satisfied: pyyaml in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras) (5.3.1)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras) (1.4.1)\nRequirement already satisfied: six in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from h5py->keras) (1.15.0)\nInstalling collected packages: keras\nSuccessfully installed keras-2.4.3\nCollecting pyspark==2.4.5\n  Downloading pyspark-2.4.5.tar.gz (217.8 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 217.8 MB 11 kB/s s eta 0:00:019\n\u001b[?25hCollecting py4j==0.10.7\n  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 197 kB 55.2 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=978e170c84817ecfa03bf1afd80355caade93b66832a556ba125f87967b6ab12\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/01/c0/03/1c241c9c482b647d4d99412a98a5c7f87472728ad41ae55e1e\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.7 pyspark-2.4.5\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\n\nsc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n\nspark = SparkSession \\\n    .builder \\\n    .getOrCreate()", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Now we need to import few other necessary libraries that will be needed and add the dataset."}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\n\n#libraries for the machine learning model\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import Normalizer\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n#libraries for the deep learning model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.utils import to_categorical", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_f1a0c12d7fb84344af027261a2aa9ba8 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='ARYhgLCYvhaUWh9CUw9--q2M6_-1sbXvh0g7wNZ5cew7',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.eu-geo.objectstorage.service.networklayer.com')\n\nbody = client_f1a0c12d7fb84344af027261a2aa9ba8.get_object(Bucket='advancedatasciencecourse-donotdelete-pr-qfeni9xv77zjog',Key='Skyserver_12_30_2019 4_49_58 PM.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf = pd.read_csv(body)\ndf.head()\n", "execution_count": 5, "outputs": [{"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "                 objid          ra        dec         u         g         r  \\\n0  1237666301628060000   47.372545   0.820621  18.69254  17.13867  16.55555   \n1  1237673706652430000  116.303083  42.455980  18.47633  17.30546  17.24116   \n2  1237671126974140000  172.756623  -8.785698  16.47714  15.31072  15.55971   \n3  1237665441518260000  201.224207  28.771290  18.63561  16.88346  16.09825   \n4  1237665441522840000  212.817222  26.625225  18.88325  17.87948  17.47037   \n\n          i         z   run  rerun  camcol  field            specobjid  \\\n0  16.34662  16.17639  4849    301       5    771  8168632633242440000   \n1  17.32780  17.37114  6573    301       6    220  9333948945297330000   \n2  15.72207  15.82471  5973    301       1     13  3221211255238850000   \n3  15.70987  15.43491  4649    301       3    121  2254061292459420000   \n4  17.17441  17.05235  4649    301       3    191  2390305906828010000   \n\n    class  redshift  plate    mjd  fiberid  \n0    STAR  0.000115   7255  56597      832  \n1    STAR -0.000093   8290  57364      868  \n2    STAR  0.000165   2861  54583       42  \n3  GALAXY  0.058155   2002  53471       35  \n4  GALAXY  0.072210   2123  53793       74  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>objid</th>\n      <th>ra</th>\n      <th>dec</th>\n      <th>u</th>\n      <th>g</th>\n      <th>r</th>\n      <th>i</th>\n      <th>z</th>\n      <th>run</th>\n      <th>rerun</th>\n      <th>camcol</th>\n      <th>field</th>\n      <th>specobjid</th>\n      <th>class</th>\n      <th>redshift</th>\n      <th>plate</th>\n      <th>mjd</th>\n      <th>fiberid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1237666301628060000</td>\n      <td>47.372545</td>\n      <td>0.820621</td>\n      <td>18.69254</td>\n      <td>17.13867</td>\n      <td>16.55555</td>\n      <td>16.34662</td>\n      <td>16.17639</td>\n      <td>4849</td>\n      <td>301</td>\n      <td>5</td>\n      <td>771</td>\n      <td>8168632633242440000</td>\n      <td>STAR</td>\n      <td>0.000115</td>\n      <td>7255</td>\n      <td>56597</td>\n      <td>832</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1237673706652430000</td>\n      <td>116.303083</td>\n      <td>42.455980</td>\n      <td>18.47633</td>\n      <td>17.30546</td>\n      <td>17.24116</td>\n      <td>17.32780</td>\n      <td>17.37114</td>\n      <td>6573</td>\n      <td>301</td>\n      <td>6</td>\n      <td>220</td>\n      <td>9333948945297330000</td>\n      <td>STAR</td>\n      <td>-0.000093</td>\n      <td>8290</td>\n      <td>57364</td>\n      <td>868</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1237671126974140000</td>\n      <td>172.756623</td>\n      <td>-8.785698</td>\n      <td>16.47714</td>\n      <td>15.31072</td>\n      <td>15.55971</td>\n      <td>15.72207</td>\n      <td>15.82471</td>\n      <td>5973</td>\n      <td>301</td>\n      <td>1</td>\n      <td>13</td>\n      <td>3221211255238850000</td>\n      <td>STAR</td>\n      <td>0.000165</td>\n      <td>2861</td>\n      <td>54583</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1237665441518260000</td>\n      <td>201.224207</td>\n      <td>28.771290</td>\n      <td>18.63561</td>\n      <td>16.88346</td>\n      <td>16.09825</td>\n      <td>15.70987</td>\n      <td>15.43491</td>\n      <td>4649</td>\n      <td>301</td>\n      <td>3</td>\n      <td>121</td>\n      <td>2254061292459420000</td>\n      <td>GALAXY</td>\n      <td>0.058155</td>\n      <td>2002</td>\n      <td>53471</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1237665441522840000</td>\n      <td>212.817222</td>\n      <td>26.625225</td>\n      <td>18.88325</td>\n      <td>17.87948</td>\n      <td>17.47037</td>\n      <td>17.17441</td>\n      <td>17.05235</td>\n      <td>4649</td>\n      <td>301</td>\n      <td>3</td>\n      <td>191</td>\n      <td>2390305906828010000</td>\n      <td>GALAXY</td>\n      <td>0.072210</td>\n      <td>2123</td>\n      <td>53793</td>\n      <td>74</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "We start doing some feature engineering as dropping the columns that are not relevant, as the ones involving \"ID\" or their coordinates, and vectorizing the brightness bands and indexing the labels."}, {"metadata": {}, "cell_type": "code", "source": "df.rename(columns={'u': 'U-band','g': 'G-band','r': 'R-band','i': 'I-band','z': 'Z-band'}, inplace=True)\ndf.drop(['objid','specobjid','fiberid'],axis=1,inplace=True)", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We convert the pandas Dataframe into a PySpark dataframe and establish the train and test datasets. "}, {"metadata": {}, "cell_type": "code", "source": "df_ml=spark.createDataFrame(df)\ndf_ml.createOrReplaceTempView(\"df_ml\")\nspark.sql(\"SELECT class,count(*) from df_ml group by class\").show()", "execution_count": 24, "outputs": [{"output_type": "stream", "text": "+------+--------+\n| class|count(1)|\n+------+--------+\n|GALAXY|   51323|\n|   QSO|   10581|\n|  STAR|   38096|\n+------+--------+\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "(train_set,test_set) = df_ml.randomSplit([0.7, 0.3], 1234)", "execution_count": 26, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We set the stages for the pipeline."}, {"metadata": {}, "cell_type": "code", "source": "feature_list=df_ml.columns\nfeature_list.remove('class')\nfeatureAssembler=VectorAssembler(inputCols=feature_list,outputCol=\"features\")\nnormalizer = Normalizer(inputCol=\"features\", outputCol=\"norm_features\", p=1.0)\nclassIndexer=StringIndexer(inputCol=\"class\", outputCol=\"class_index\")", "execution_count": 35, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Considering our problem a classification model seems appropiate, for example GBT one."}, {"metadata": {}, "cell_type": "code", "source": "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n\nDtree=DecisionTreeClassifier(labelCol='class_index', featuresCol='norm_features')\nRandforest=RandomForestClassifier(labelCol='class_index', featuresCol='norm_features',numTrees=5)", "execution_count": 36, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We set the pipeline and train the model."}, {"metadata": {}, "cell_type": "code", "source": "pipe=Pipeline(stages=[featureAssembler,normalizer,classIndexer,Dtree])\npipe1=Pipeline(stages=[featureAssembler,normalizer,classIndexer,Randforest])", "execution_count": 37, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "ml_model = pipe.fit(train_set)\nml_model1 = pipe1.fit(train_set)", "execution_count": 38, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We now evalute the model and it's precision."}, {"metadata": {}, "cell_type": "code", "source": "pred_ml = ml_model.transform(test_set)\npred_ml1 = ml_model1.transform(test_set)", "execution_count": 39, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "binEval = MulticlassClassificationEvaluator().setMetricName(\"accuracy\") .setPredictionCol(\"prediction\").setLabelCol(\"class_index\")\n    \nml_accuracy=binEval.evaluate(pred_ml)\nml_accuracy1=binEval.evaluate(pred_ml1)\nprint('Accuracy for Decision Tree: ',ml_accuracy)\nprint('Accuracy for Random Forest: ',ml_accuracy1)", "execution_count": 40, "outputs": [{"output_type": "stream", "text": "Accuracy for Decision Tree:  0.9780354888017545\nAccuracy for Random Forest:  0.9626503621984449\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "We manage to get a 97% of accuracy determining the object via the machine learning model. Now we build the deep learning model for comparison, also, we need to reset the train and test set."}, {"metadata": {}, "cell_type": "markdown", "source": "In order to set the train and test set for the neural network we need to convert again the pyspark dataframe to a pandas dataframe."}, {"metadata": {}, "cell_type": "code", "source": "df.shape", "execution_count": 443, "outputs": [{"output_type": "execute_result", "execution_count": 443, "data": {"text/plain": "(100000, 15)"}, "metadata": {}}]}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "df_labels=df[['class']]\ndf_features=df.drop('class',axis=1)", "execution_count": 444, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.preprocessing import LabelEncoder\n\nlabs=LabelEncoder().fit_transform(df_labels)\n\ndf_labels['class_encoded']=labs\ndf_labels.drop('class',axis=1,inplace=True)\ndf_labels.head()", "execution_count": 445, "outputs": [{"output_type": "stream", "text": "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(**kwargs)\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  errors=errors,\n", "name": "stderr"}, {"output_type": "execute_result", "execution_count": 445, "data": {"text/plain": "   class_encoded\n0              2\n1              2\n2              2\n3              0\n4              0", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "samples=df_features.shape[0]\ndimensions=df_features.shape[1]\n\nfeature_train, feature_test, label_train, label_test = train_test_split(df_features, df_labels, test_size=0.3)\nfeature_train, feature_validation, label_train, label_validation = train_test_split(feature_train, label_train, test_size=0.3)", "execution_count": 498, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We build the neural network and train it."}, {"metadata": {}, "cell_type": "code", "source": "epochs = 5\n\nnn_model=Sequential()\nnn_model.add(Dense(15, input_shape=(dimensions, ), activation='softmax'))\nnn_model.add(Dropout(0.3))\n#nn_model.add(Dense(15, activation='softmax'))\nnn_model.add(Dense(3, activation='softmax'))\nnn_model.compile(loss='binary_crossentropy', optimizer=\"adam\")", "execution_count": 501, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "nn_model.fit(feature_train, label_train, epochs=epochs, batch_size=60, validation_data=(feature_validation, label_validation), verbose=0, shuffle=True)", "execution_count": 502, "outputs": [{"output_type": "execute_result", "execution_count": 502, "data": {"text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f43dc0ae150>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "It's time to test the accuracy of the neural network."}, {"metadata": {}, "cell_type": "code", "source": "test_pred=nn_model.predict(feature_test)\n\ncorrect=0\nfor i in range(len(test_pred)):\n    label_pred=np.argmax(test_pred[i])\n    if label_pred==label_test['class_encoded'].tolist()[i]:\n        correct+=1\n        \nprint('Accuracy of the neural network is: ',correct/len(test_pred))", "execution_count": 503, "outputs": [{"output_type": "stream", "text": "Accuracy of the neural network is:  0.5137\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}